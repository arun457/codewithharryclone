<!DOCTYPE html><html lang="en">
<!-- Mirrored from www.codewithharry.com/videos/python-web-scraping-tutorial-in-hindi/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 01 Aug 2021 14:00:09 GMT -->
<head>
  <meta charset="utf-8">
  <title>Web Scraping Tutorial using Python and BeautifulSoup - CodeWithHarry</title>
  <base >
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" type="image/x-icon" href="../../favicon.ico">
  <link rel="preconnect" href="https://fonts.gstatic.com/">
  <style type="text/css">@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103, U+0110-0111, U+0128-0129, U+0168-0169, U+01A0-01A1, U+01AF-01B0, U+1EA0-1EF9, U+20AB;}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu72xKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu5mxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu7mxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu4WxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu7WxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0102-0103, U+0110-0111, U+0128-0129, U+0168-0169, U+01A0-01A1, U+01AF-01B0, U+1EA0-1EF9, U+20AB;}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu7GxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu4mxKKTU1Kg.woff2) format('woff2');unicode-range:U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF;}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-03FF;}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103, U+0110-0111, U+0128-0129, U+0168-0169, U+01A0-01A1, U+01AF-01B0, U+1EA0-1EF9, U+20AB;}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;}</style>
  <style type="text/css">@font-face{font-family:'Material Icons';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/materialicons/v87/flUhRq6tzZclQEJ-Vdg-IuiaDsNcIhQ8tQ.woff2) format('woff2');}.material-icons{font-family:'Material Icons';font-weight:normal;font-style:normal;font-size:24px;line-height:1;letter-spacing:normal;text-transform:none;display:inline-block;white-space:nowrap;word-wrap:normal;direction:ltr;-webkit-font-feature-settings:'liga';-webkit-font-smoothing:antialiased;}</style>
  <script data-ad-client="ca-pub-9655830461045889" async="" src="../../../pagead2.googlesyndication.com/pagead/js/f.txt"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-60726752-3"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-60726752-3');
  </script>
<link rel="stylesheet" href="../../styles.bc31d58d1fffbdf64e6b.css"><style ng-transition="serverApp">.content[_ngcontent-sc76]{min-height:calc(100vh - 56px - 80px)}</style><style ng-transition="serverApp">[_nghost-sc73]{position:relative;display:block;pointer-events:none}[_nghost-sc73]   .ngx-spinner[_ngcontent-sc73]{transition:350ms linear;display:block;position:absolute;top:5px;left:0}[_nghost-sc73]   .ngx-spinner[_ngcontent-sc73]   .ngx-spinner-icon[_ngcontent-sc73]{width:14px;height:14px;border:2px solid transparent;border-top-color:inherit;border-left-color:inherit;border-radius:50%;-webkit-animation:.4s linear infinite loading-bar-spinner;animation:.4s linear infinite loading-bar-spinner}[_nghost-sc73]   .ngx-bar[_ngcontent-sc73]{transition:width 350ms;position:absolute;top:0;left:0;width:100%;height:2px;border-bottom-right-radius:1px;border-top-right-radius:1px}[dir=rtl]   [_nghost-sc73]   .ngx-bar[_ngcontent-sc73]{right:0;left:unset}[fixed=true][_nghost-sc73]{z-index:10002}[fixed=true][_nghost-sc73]   .ngx-bar[_ngcontent-sc73]{position:fixed}[fixed=true][_nghost-sc73]   .ngx-spinner[_ngcontent-sc73]{position:fixed;top:10px;left:10px}[dir=rtl]   [fixed=true][_nghost-sc73]   .ngx-spinner[_ngcontent-sc73]{right:10px;left:unset}@-webkit-keyframes loading-bar-spinner{0%{transform:rotate(0)}100%{transform:rotate(360deg)}}@keyframes loading-bar-spinner{0%{transform:rotate(0)}100%{transform:rotate(360deg)}}</style><style ng-transition="serverApp">.brandLogo[_ngcontent-sc74]{max-width:39px;margin:0 13px}li[_ngcontent-sc74]   a.nav-link[_ngcontent-sc74]{color:#fff}.notificationImg[_ngcontent-sc74]{width:30px;filter:invert(1)}.notification-bell[_ngcontent-sc74]{position:absolute;right:0}.dropdown-toggle[_ngcontent-sc74]{font-weight:700}.dropdown-menu-notify[_ngcontent-sc74]{overflow-y:scroll;overflow-x:hidden;max-height:400px;top:60px;right:-1px;left:unset;width:460px;box-shadow:0 5px 7px -1px #c1c1c1;padding:0}ul[_ngcontent-sc74]   ul[_ngcontent-sc74]   a[_ngcontent-sc74]{background:transparent}.dropdown-menu-notify[_ngcontent-sc74]:before{content:"";position:absolute;top:-20px;right:12px;border:10px solid transparent;border-bottom-color:#fff}.head-notify[_ngcontent-sc74]{padding:5px 15px;border-radius:3px 3px 0 0}.footer-notify[_ngcontent-sc74]{padding:5px 15px;border-radius:0 0 3px 3px}.notification-box-notify[_ngcontent-sc74]{padding:10px 0}.bg-gray-notify[_ngcontent-sc74]{background-color:#eee}@media (max-width:640px){.dropdown-menu-notify[_ngcontent-sc74]{top:50px;left:-16px;width:290px}.nav-notify[_ngcontent-sc74]{display:block}.nav-notify[_ngcontent-sc74]   .nav-item-notify[_ngcontent-sc74], .nav-notify[_ngcontent-sc74]   .nav-item-notify[_ngcontent-sc74]   a[_ngcontent-sc74]{padding-left:0}.message-notify[_ngcontent-sc74]{font-size:13px}}.loginError[_ngcontent-sc74]{color:red;padding:3px 2px}div.alert[_ngcontent-sc74]{margin:0}input.ng-touched.ng-invalid[_ngcontent-sc74], textarea.ng-touched.ng-invalid[_ngcontent-sc74]{border-color:red}.forgot[_ngcontent-sc74]{font-size:14px;color:#000;text-align:left;text-decoration:underline;cursor:pointer;padding:16px 0}.googleAuth[_ngcontent-sc74]{width:46%;cursor:pointer;border:1px solid #000;border-radius:3px;background:#60a3dd;margin-top:1px}.or[_ngcontent-sc74]{font-weight:500;font-size:19px}.modal-header[_ngcontent-sc74]{display:flex;align-items:center;justify-content:center;flex-direction:column}.modal-header[_ngcontent-sc74]   span[_ngcontent-sc74]{position:absolute;top:15px;right:20px}.navbar-brand[_ngcontent-sc74]{margin:0;padding:0}</style><style ng-transition="serverApp">footer[_ngcontent-sc75]{color:#fff}</style><style ng-transition="serverApp">div.code-toolbar{position:relative}div.code-toolbar>.toolbar{position:absolute;top:.3em;right:.2em;transition:opacity .3s ease-in-out;opacity:0}div.code-toolbar:focus-within>.toolbar,div.code-toolbar:hover>.toolbar{opacity:1}div.code-toolbar>.toolbar .toolbar-item{display:inline-block}div.code-toolbar>.toolbar a{cursor:pointer}div.code-toolbar>.toolbar button{background:none;border:0;color:inherit;font:inherit;line-height:normal;overflow:visible;padding:0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none}div.code-toolbar>.toolbar a,div.code-toolbar>.toolbar button,div.code-toolbar>.toolbar span{color:#bbb;font-size:.8em;padding:0 .5em;background:#f5f2f0;background:hsla(0,0%,87.8%,.2);box-shadow:0 2px 0 0 rgba(0,0,0,.2);border-radius:.5em}div.code-toolbar>.toolbar a:focus,div.code-toolbar>.toolbar a:hover,div.code-toolbar>.toolbar button:focus,div.code-toolbar>.toolbar button:hover,div.code-toolbar>.toolbar span:focus,div.code-toolbar>.toolbar span:hover{color:inherit;text-decoration:none}code[class*=language-],pre[class*=language-]{color:#f8f8f2;background:none;text-shadow:0 1px rgba(0,0,0,.3);font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;tab-size:4;-webkit-hyphens:none;hyphens:none}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto;border-radius:.3em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#272822}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#8292a2}.token.punctuation{color:#f8f8f2}.token.namespace{opacity:.7}.token.constant,.token.deleted,.token.property,.token.symbol,.token.tag{color:#f92672}.token.boolean,.token.number{color:#ae81ff}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#a6e22e}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url,.token.variable{color:#f8f8f2}.token.atrule,.token.attr-value,.token.class-name,.token.function{color:#e6db74}.token.keyword{color:#66d9ef}.token.important,.token.regex{color:#fd971f}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}code[class*=language-],pre[class*=language-]{max-height:614px}.commentContainer{overflow-x:auto}.content-holder{list-style:none;padding:0}.content-holder a{color:#000;text-decoration:none}.content-holder li:hover{background-color:#efeff0}.content-holder-item{padding:23px 12px;font-size:16px;cursor:pointer}li.active{background-color:#d6d6d6}.bg-black{background-color:#000}#content-box{max-height:85vh;overflow-y:scroll}#course-content-box{background:#fff;align-self:flex-start;height:20px;position:sticky;top:0}.bg-lgrey{background-color:#e7e7e9}.tab-pane{min-height:344px}.nav-link{font-weight:700;color:#000}.commentReplies{background-color:#e7e7e9;margin:18px 3px}.commentReplies img{margin:8px 14px}#toggleCourse{display:none}.openCourseHeight{height:76vh!important}.plusIcon{display:none}@media only screen and (max-width:400px){.nav-link{font-size:16px;padding:9px 6px}#course-content-box{height:57px}}@media only screen and (max-width:560px){img.rounded-circle{height:0;visibility:hidden}}@media only screen and (max-width:768px){#course-content-box{height:46px;transition:height .4s;position:static}#content-box{height:70vh;visibility:hidden}#toggle-button{visibility:visible}#video-box{z-index:1}#sticky-d{position:sticky;top:0;z-index:1}#toggleCourse{display:inline}.other{margin-left:-15px;margin-right:-15px}.plusIcon{display:inline-block;width:24px;height:24px}}#video-box2{font-size:14pt;font-family:helvetica}#video-box2 img{cursor:pointer}#video-box2 pre code{font-size:16px}.commentContainer pre{font-size:14pt;font-family:helvetica}#video-box2 h6,h1,h2,h3,h4,h5{font-family:Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}.tab-pane{min-height:100vh}div.toolbar-item button{color:#fff!important;border:2px solid #fff!important;margin-right:23px}@media screen and (max-width:768px){div.toolbar-item button{margin-right:0}}#previewModal .modal-dialog{max-width:80%}.h-0{height:0}@media screen and (max-width:768px){div.toolbar-item button{margin-right:0}#video-box2 pre code{font-size:10px}.mt-48{margin-top:48px}}pre[class*=language-]{font-size:6pt}img{max-width:100%;height:auto}#video-box2{word-wrap:break-word}.commentError{font-size:10pt;margin:8px}#qna>h2{margin:43px}.showReplies{color:#00f;cursor:pointer;font-size:14px;padding:8px 16px}.advh{height:300px;width:100%;margin:auto}h2,h3,h4,h5,h6{margin:25px 0 9px}.commentPre{overflow-x:auto;white-space:pre-wrap;white-space:-moz-pre-wrap;white-space:-pre-wrap;white-space:-o-pre-wrap;word-wrap:break-word}table{max-width:90vw}td,tr{max-width:30vw!important}</style><meta name="description" content="In this tutorial we will learn about creating web scraping using python and beautiful soup"><style ng-transition="serverApp"></style></head>

<body>
  <app-root _nghost-sc76="" ng-version="11.2.11"><ngx-loading-bar _ngcontent-sc76="" _nghost-sc73="" fixed="true" style="color:red;"><!----></ngx-loading-bar><ngx-loading-bar _ngcontent-sc76="" _nghost-sc73="" fixed="true" style="color:red;"><!----></ngx-loading-bar><app-header _ngcontent-sc76="" _nghost-sc74=""><!----><nav _ngcontent-sc74="" class="navbar navbar-expand-lg navbar-dark bg-dark"><a _ngcontent-sc74="" routerlink="/" class="navbar-brand" href="../../index.html"><img _ngcontent-sc74="" height="39px" width="39px" src="../../assets/img/logo.png" alt="CodeWithHarry" class="brandLogo"></a><button _ngcontent-sc74="" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler"><span _ngcontent-sc74="" class="navbar-toggler-icon"></span></button><div _ngcontent-sc74="" id="navbarSupportedContent" class="collapse navbar-collapse"><ul _ngcontent-sc74="" class="navbar-nav mr-auto"><li _ngcontent-sc74="" class="nav-item font-weight-bold"><a _ngcontent-sc74="" routerlink="/" class="nav-link" href="../../index.html">Home</a></li><li _ngcontent-sc74="" class="nav-item font-weight-bold"><a _ngcontent-sc74="" routerlink="/videos" class="nav-link" href="../index.html">Videos</a></li><li _ngcontent-sc74="" class="nav-item font-weight-bold"><a _ngcontent-sc74="" routerlink="/blog" class="nav-link" href="../../blog/index.html">Blog</a></li><li _ngcontent-sc74="" class="nav-item font-weight-bold"><a _ngcontent-sc74="" routerlink="/contact" class="nav-link" href="../../contact/index.html">Contact Me</a></li></ul><form _ngcontent-sc74="" novalidate="" class="form-inline my-2 my-lg-0 mr-3 ng-untouched ng-pristine ng-valid"><input _ngcontent-sc74="" type="text" placeholder="Search" aria-label="Search" name="query" class="form-control mr-sm-2 ng-untouched ng-pristine ng-valid" value=""><button _ngcontent-sc74="" type="submit" class="btn btn-danger my-2 my-sm-0">Search</button></form><div _ngcontent-sc74="" class="mx-0"><button _ngcontent-sc74="" type="button" data-toggle="modal" data-target="#loginModal" class="btn btn-danger mr-2">Login</button><button _ngcontent-sc74="" type="button" data-toggle="modal" data-target="#signupModal" class="btn btn-danger">SignUp</button></div><!----><!----></div></nav><div _ngcontent-sc74="" id="loginModal" tabindex="-1" role="dialog" aria-labelledby="loginModal" aria-hidden="true" class="modal fade"><div _ngcontent-sc74="" role="document" class="modal-dialog"><div _ngcontent-sc74="" class="modal-content"><div _ngcontent-sc74="" class="modal-header"><img _ngcontent-sc74="" height="42.75px" width="25%" src="../../assets/img/googleLogin.png" alt="Login with Google" class="googleAuth mx-2"><div _ngcontent-sc74="" class="or mx-3"> or </div><h5 _ngcontent-sc74="" id="loginModalTitle" class="modal-title">Login via username</h5><button _ngcontent-sc74="" type="button" data-dismiss="modal" aria-label="Close" class="close"><span _ngcontent-sc74="" aria-hidden="true">×</span></button></div><div _ngcontent-sc74="" class="modal-body"><form _ngcontent-sc74="" novalidate="" method="post" class="ng-untouched ng-pristine ng-invalid"><div _ngcontent-sc74="" class="form-group"><label _ngcontent-sc74="" for="username">Username</label><input _ngcontent-sc74="" type="text" id="username" placeholder="Enter your username" name="username" pattern="[a-zA-Z0-9 ]*" maxlength="10" minlength="2" required="" class="form-control ng-untouched ng-pristine ng-invalid" value=""><!----></div><div _ngcontent-sc74="" class="form-group"><label _ngcontent-sc74="" for="loginpassword">Password</label><input _ngcontent-sc74="" type="password" id="loginpassword" placeholder="Enter your password" name="loginpassword" required="" class="form-control ng-untouched ng-pristine ng-invalid" value=""></div><button _ngcontent-sc74="" type="submit" id="loginsubmit" class="btn btn-danger mt-2" disabled=""><!----> Login</button></form><!----><!----><!----><div _ngcontent-sc74="" class="forgot"><span _ngcontent-sc74="">Forgot Password?</span></div></div><div _ngcontent-sc74="" class="modal-footer"><button _ngcontent-sc74="" type="button" data-dismiss="modal" class="btn btn-secondary">Close</button></div></div></div></div><div _ngcontent-sc74="" id="signupModal" tabindex="-1" role="dialog" aria-labelledby="signupModal" aria-hidden="true" class="modal fade"><div _ngcontent-sc74="" role="document" class="modal-dialog"><div _ngcontent-sc74="" class="modal-content"><div _ngcontent-sc74="" class="modal-header"><img _ngcontent-sc74="" height="42.75px" width="25%" src="../../assets/img/googleSignUp.png" alt="Signup with Google" class="googleAuth mx-2"><div _ngcontent-sc74="" class="or mx-3"> or </div><h5 _ngcontent-sc74="" id="signupModal" class="modal-title">SignUp for an account</h5><button _ngcontent-sc74="" type="button" data-dismiss="modal" aria-label="Close" class="close"><span _ngcontent-sc74="" aria-hidden="true">×</span></button></div><div _ngcontent-sc74="" class="modal-body"><form _ngcontent-sc74="" novalidate="" method="post" class="ng-untouched ng-pristine ng-invalid"><div _ngcontent-sc74="" class="form-group"><label _ngcontent-sc74="" for="uname">Username</label><input _ngcontent-sc74="" type="text" id="signupUserName" placeholder="Enter your username" name="signupUserName" pattern="[a-zA-Z0-9_ ]*" maxlength="10" minlength="4" required="" ngmodel="" class="form-control ng-untouched ng-pristine ng-invalid" value=""><!----><small _ngcontent-sc74="" id="unamehelp" class="form-text text-muted px-1"> Your unique username must 4 - 10 characters (only lowecase letters, numbers &amp; underscores allowed) with no spaces </small></div><div _ngcontent-sc74="" class="form-group"><label _ngcontent-sc74="" for="signupName">Name</label><input _ngcontent-sc74="" type="text" id="signupName" name="signupName" placeholder="Enter your Name" maxlength="30" ngmodel="" class="form-control ng-untouched ng-pristine ng-valid" value=""></div><div _ngcontent-sc74="" class="form-group"><label _ngcontent-sc74="" for="email">Your Email</label><div _ngcontent-sc74="" class="mx-0"><div _ngcontent-sc74="" class="col-md-8 px-0"><input _ngcontent-sc74="" type="email" placeholder="Enter your Email" id="signupEmail" name="signupEmail" required="" email="" maxlength="40" class="form-control ng-untouched ng-pristine ng-invalid" value=""><!----><!----></div><div _ngcontent-sc74="" class="col-md-4 my-1 px-0"><button _ngcontent-sc74="" type="button" id="otpbtn" class="btn btn-danger btn-sm mt-2" disabled=""><!----> Send OTP</button></div></div></div><div _ngcontent-sc74="" class="form-group"><label _ngcontent-sc74="" for="otp">Enter OTP</label><input _ngcontent-sc74="" type="number" id="signupOTP" placeholder="Enter OTP" name="signupOTP" required="" ngmodel="" class="form-control ng-untouched ng-pristine ng-invalid" value=""></div><div _ngcontent-sc74="" class="form-group"><label _ngcontent-sc74="" for="signupPassword1">Choose a password (At least 4 characters)</label><input _ngcontent-sc74="" type="password" id="signupPassword1" name="signupPassword1" placeholder="Choose a password" minlength="4" maxlength="20" ngmodel="" class="form-control ng-untouched ng-pristine ng-valid" value=""></div><div _ngcontent-sc74="" class="form-group mb-0"><label _ngcontent-sc74="" for="signupPassword2">Retype your password</label><input _ngcontent-sc74="" type="password" id="signupPassword2" name="signupPassword2" placeholder="Retype your password" minlength="4" maxlength="20" ngmodel="" class="form-control ng-untouched ng-pristine ng-valid" value=""></div><!----><!----><!----><!----><button _ngcontent-sc74="" type="submit" class="btn btn-danger mt-4" disabled=""><!----> SignUp</button></form></div><div _ngcontent-sc74="" class="modal-footer"><button _ngcontent-sc74="" type="button" data-dismiss="modal" class="btn btn-secondary">Close</button></div></div></div></div></app-header><div _ngcontent-sc76="" class="content"><router-outlet _ngcontent-sc76=""></router-outlet><app-video-page><div class="container-fluid"><div id="sticky-d" class="row"><div id="video-box" class="col-md-9 bg-black px-0"><div class="container videoContainer embed-responsive embed-responsive-16by9 px-3"><iframe allowfullscreen="" class="embed-responsive-item" src="https://www.youtube.com/embed/uufDGjTuq34"></iframe><!----></div><!----></div><div id="course-content-box" class="col-md-3 px-0"><div class="row mx-0 py-2 px-3 bg-lgrey"><h5 class="my-0"> Course Content </h5><img height="25px" width="25px" alt="" class="plusIcon mx-2" src="../../assets/img/plus.png"><button id="togglePlayer" class="btn btn-sm btn-danger mx-3">Hide  Player</button></div><div id="content-box" class=""><ul class="content-holder"><li class="content-holder-item"><input type="checkbox"> 1. Learn JavaScript In One Video In Hindi (2018) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 2. Learn Python In Hindi In One Video - हिंदी में (Latest Tutorial) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 3. Learn Php In One Video In Hindi - हिंदी में (Latest PHP Tutorial 2018) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 4. 15 Minute Python Tutorial For Beginners In Hindi (Full &amp; Complete Crash Course) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 5. Learn Bootstrap In Hindi In One Video - हिंदी में (Latest Tutorial 2019) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 6. Learn HTML In One Video <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 7. Learn jQuery In Hindi In One Video - हिंदी में (Latest Tutorial 2018) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 8. Create A Responsive Website Using HTML, CSS And Bootstrap 4 In Hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 9. Login And Registration Form Using Php &amp; MySQL [Php Login System In Hindi] <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 10. C Programming Tutorial For Beginners: Learn C In Hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 11. JavaScript Registration Form Validation - हिंदी में (Latest Tutorial 2019) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 12. CSS 3 Tutorial For Beginners: Learn CSS In One Video In Hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 13. C++ Tutorial For Beginners: Learn C Plus Plus In Hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 14. Learn Python Programming For Free | Python Programming Tutorial In Hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 15. Java tutorial in hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 16. Android Development Tutorial in Hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item active"><input type="checkbox"> 17. Web Scraping Tutorial using Python and BeautifulSoup <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 18. Git &amp; GitHub Tutorial For Beginners In Hindi - हिंदी में (2019) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 19. Login And Registration Form Using Php &amp; MySQL [Php Login System In Hindi] <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 20. Linux Tutorial For Beginners in Hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 21. Numpy Tutorial in Hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 22. Php Tutorial for Beginners in Hindi with MySQL Project <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 23. Learn JavaScript In One Video In Hindi (2020) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 24. C Language Tutorial For Beginners (With Notes) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 25. How To Make a WordPress Website | Wordpress Tutorial for Beginners | Elementor Tutorial In Hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 26. Python Tutorial For Beginners In Hindi (With Notes) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 27. Python Programming Course in Hindi (Advanced) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 28. Android Application Development Tutorial in Hindi With Notes <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 29. React Tutorial in Hindi <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 30. HTML Tutorial For Beginners In Hindi (With Notes) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><li class="content-holder-item"><input type="checkbox"> 31. CSS Tutorial In Hindi (With Notes) <div class="mx-3"><i class="far fa-play-circle"></i> Free YouTube Video </div></li><!----></ul><!----></div></div><hr></div><div id="video-box2" class="col-md-9 bg-black px-0"><div class="other bg-light"><ul id="myTab" role="tablist" class="nav nav-tabs"><li role="presentation" class="nav-item"><a id="overview-tab" data-toggle="tab" href="#overview" role="tab" aria-controls="overview" aria-selected="true" class="nav-link active">Overview</a></li><li role="presentation" class="nav-item"><a id="qna-tab" data-toggle="tab" href="#qna" role="tab" aria-controls="qna" aria-selected="false" class="nav-link">Q&amp;A</a></li><li role="presentation" class="nav-item"><a id="resources-tab" data-toggle="tab" href="#resources" role="tab" aria-controls="resources" aria-selected="false" class="nav-link">Files</a></li><li role="presentation" class="nav-item"><a id="announcements-tab" data-toggle="tab" href="#announcements" role="tab" aria-controls="announcements" aria-selected="false" class="nav-link">Announcements</a></li></ul><div id="myTabContent" class="tab-content"><div id="overview" role="tabpanel" aria-labelledby="overview-tab" class="tab-pane fade show mx-4 mt-3 active"><div class="container clearfix py-0 px-0"><h3 class="my-2"> Web Scraping Tutorial using Python and BeautifulSoup<a target="_blank" href="https://www.codewithharry.com/dashboard/videos/python-web-scraping-tutorial-in-hindi"><!----></a></h3><!----><div class="contentBox"><div><h4>Introduction:</h4>
<p>In this blog we will learn web scrapping from start to end. We will cover topics like:</p>
<ul>
<li><a href="#webback">How does a website works in the backend?</a></li>
<li><a href="#webscr">What is web scrapping?</a></li>
<li><a href="#insmod">Installing modules:</a>
<ul>
<li><a href="#usemod">Why use modules?</a></li>
<li><a href="#howins">How to install modules?</a></li>
</ul>
</li>
<li><a href="#req">Requests</a>
<ul>
<li><a href="#getdata">Getting data(HTML)</a></li>
</ul>
</li>
<li><a href="../../mainbs4.html">BeautifulSoup (bs4)</a>
<ul>
<li><a href="#pardata">Parsing Data</a></li>
<li><a href="#htmltt">HTML Tree Traversal (Targeting Data)</a>
<ul>
<li><a href="#ofir">Our First Code(Getting title)</a></li>
<li><a href="#find">find()</a></li>
<li><a href="#fall">find_all()</a></li>
<li><a href="#gcae">Getting class of an element</a></li>
<li><a href="#fecn">Finding elements through class name</a></li>
<li><a href="#feid">Finding elements through element ID</a></li>
<li><a href="#gtgt">Getting text from tags(text/get_text())</a></li>
<li><a href="#gatl">Getting all the links</a></li>
<li><a href="#thtmlreq">Taking HTML from a variable instead of requests</a></li>
<li><a href="#cont">Contents</a></li>
<li><a href="#cpnp">Children, parent, next_sibling and previous_siblings</a></li>
<li><a href="#dbcc">Difference between children and contents</a></li>
<li><a href="#sdss">stripped_strings</a></li>
<li><a href="#exit">exit()</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#wcsv">Writing data in CSV file</a></li>
<li><a href="#tip">Tip</a></li>
</ul>
<p></p></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>How does a website works in the backend?</h4>
<p>Step 1: User requests a page. Eg:- <a href="http://www.google.com/">www.google.com</a></p>
<p>Step 2: On whichever server the data is, that server sends you back a raw html file.</p>
<p><img src="../../../api.codewithharry.com/media/videoSeriesFiles/courseFiles/python-web-scraping-tutorial-in-hindi/files.jpg" alt="" width="1366" height="621"></p>
<p><img src="../../../api.codewithharry.com/media/videoSeriesFiles/courseFiles/python-web-scraping-tutorial-in-hindi/htmlreturn.jpg" alt="" width="1366" height="621"></p>
<p>Step 3: Web browser converts the html file into a readable webpage(the one that you are seeing right now).</p>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>What is web scrapping?</h4>
<p>The technique of taking the html file sent by the server into python and scrapping it instead of giving it to the browser and displaying it is called Web scrapping.</p>
<p>Two ways of getting data from a website:</p>
<ol>
<li>Using API</li>
<li>HTML web scrapping using some tool like bs4</li>
</ol>
<h4>Installing modules:</h4>
<h5>Why use modules?</h5>
<p>In order to use the power of python to scrap websites, we don’t have to write new code for everything. We can use existing code written by experts. Why take the hard path when the outcome is same, when you can do it easily in some lines of code in very short period of time?</p>
<h5>How to install modules?</h5>
<p>Modules are very easy to install. Open command prompt and just write these three lines one by one:</p>
<pre class="language-python"><code>pip install requests
pip install html5lib
pip install bs4</code></pre>
<p>and you are good to go! If you get any error you can watch this video:</p>
<p><a href="../general-python-errors-1/index.html" target="_blank" rel="noopener">https://www.codewithharry.com/videos/general-python-errors-1</a></p>
<h4>Requests:</h4>
<ul>
<li>
<h5>Getting data(HTML):</h5>
</li>
</ul>
<p>In order to work with the HTML, we will have to get the HTML as a string. We can easily get HTML data by using get() function in requests module. We first need to import this module by writing:</p>
<pre class="language-python"><code>import requests</code></pre>
<p>Then we can make a variable or directly write the link in get() function as a string:</p>
<pre class="language-python"><code>url = "https://codewithharry.com"
r = requests.get(url)		# r variable has all the HTML code
htmlContent = r.content	# r returns response so if we want the code we write r.content
print(htmlContent)		# printing the code</code></pre>
<p><img src="../../../api.codewithharry.com/media/videoSeriesFiles/courseFiles/python-web-scraping-tutorial-in-hindi/content.jpg" alt="" width="1306" height="621"></p>
<p>Instead of “content” we can also use “text”:</p>
<pre class="language-python"><code>htmlTexr = r.text
print(htmlText)</code></pre>
<p><img src="../../../api.codewithharry.com/media/videoSeriesFiles/courseFiles/python-web-scraping-tutorial-in-hindi/text.jpg" alt="" width="1311" height="639"></p>
<p>r.text is the response in <strong>Unicode</strong> and r.content is the response in <strong>bytes</strong>.</p>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>BeautifulSoup (bs4):</h4>
<p>Beautiful Soup is the perfect module to parse or transverse through HTML code. We can easily target any div, table, td, tr, class, id, etc. The basic template(boilerplate code) which is used everytime is:</p>
<pre class="language-python"><code>import requests
from bs4 import BeautifulSoup
url = "https://codewithharry.com"

r = requests.get(url)
soup = BeautifulSoup(r.content, 'html.parser')

print(soup.prettify())	# to print html in tree structure</code></pre>
<h4>Parsing Data:</h4>
<p>Once the HTML is fetched using requests the next step will be to parse the HTML content. For that we will use python’s BeautifulSoup module which will create a tree like structure for our DOM. This line is parsing the data:</p>
<pre class="language-python"><code>soup = BeautifulSoup(htmlContent, 'html.parser')</code></pre>
<p>We have given two arguments to BeautifulSoup function. One is our HTML content another is our parser. We can also save an HTML file instead of getting data everytime, take that HTML file’s data in a variable and in the same way just write the variable in the function, both are same things. In second argument we are giving it a parser. Here we are using html.parser, we can also use lxml. The parsed data is saved in our soup variable. That is our soup, a mixture of everything. All the data we want is there, we just have to target it and get it. Simple, right?</p>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>HTML Tree Traversal (Targeting Data):</h4>
<p>From here the main thing starts, from here we start playing with the data. HTML Tree traversal is travelling through the tree branches(HTML tags) and to target the branches we want and scrapping them. Just for excitement wanna see something? Copy and run this code:</p>
<pre class="language-python"><code>import requests
from bs4 import BeautifulSoup
url = "https://www.codewithharry.com/videos/python-web-scraping-tutorial-in-hindi"

r = requests.get(url)
soup = BeautifulSoup(r.content, 'html.parser')
for i in soup.find_all("code"):
    print(i.text)
    # We can also do it like this
    # print(i.get_text())</code></pre>
<p>Yes! It scrapped all the codes on this page! See how powerful scrapping is, how much it can help you and how much time it can save! I hope you are all powered up, let’s start scrapping!</p>
<h4>Our first code:</h4>
<p>If we want to scrap title of the page(which is shown in the tab button) then we can get it by:</p>
<pre class="language-python"><code>title = soup.title
print(title)</code></pre>
<p>There is a title tag in all HTML pages, for this page it is:</p>
<pre class="language-markup"><code>&lt;title&gt;Web Scraping Tutorial using Python and BeautifulSoup in Hindi - Code With Harry&lt;/title&gt;</code></pre>
<p>So with soup.title we can directly get the title of the page. soup.title is like saying soup&gt;title, going inside soup and getting title. In windows like we go into folders like that soup/title. If say there is code:</p>
<pre class="language-markup"><code>&lt;div&gt;
    &lt;div&gt;
        &lt;code&gt;
            This is file.
        &lt;/code&gt;
    &lt;/div&gt;
&lt;/div&gt;</code></pre>
<p>We can get data of code tag by simply writing “soup.div.div.code”. It’s like giving path of a file through folders where every tag is a folder and whatever is in code tag is the file.</p>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>find():</h4>
<p>It is used to get first element in the HTML page. It could be any element. For eg:</p>
<pre class="language-python"><code>print(soup.find('p')) </code></pre>
<p>This line will get you first p tag of the page. If we want all paragraphs(all p tags) of the page then we can use find_all() function.</p>
<h4>find_all():</h4>
<p>This line will get you all p tags of the page:</p>
<pre class="language-python"><code>paras = soup.find_all('p')
print(paras)</code></pre>
<p>Whatever tag you want to scrap, write that tag in the function as argument. Also when we print paras variable,&nbsp; it will print it like a list. If we want every item one by one, we just put it through a for loop and iterate it, like this:</p>
<pre class="language-python"><code>for i in paras:
    print(i)</code></pre>
<p>gcae fecn feid gtgt gatl cont cpnp dbcc sdss</p>
<h4>Getting class of an element:</h4>
<p>Earlier we were getting text from the tag, this time we are getting class of the element. To get class of an element we need to write:</p>
<pre class="language-python"><code># print(soup.find('p')['class'])</code></pre>
<p>Here we are using find() function to get p tag like before but we added [‘class’] in it. It’s like list slicing, tag has a class variable, we are getting that variable’s value. If we want other variables like id, style, role, type, <strong>we can get them all</strong>.</p>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>Finding elements through class name:</h4>
<p>Most of the times we don’t want to find by tag name because it isn’t that accurate so we use class name there. Code to find elements by class name:</p>
<pre class="language-python"><code># print(soup.find_all("p", class_="lead"))</code></pre>
<p>We can also avoid writing tag name if you are not sure about tag name. You can simply write like:</p>
<pre class="language-python"><code># print(soup.find_all(class_="code-toolbar"))</code></pre>
<h4>Finding elements through element ID:</h4>
<p>Sometimes some elements are not given classes or we just want to target the element with id. We can do it like this:-</p>
<pre class="language-python"><code># print(soup.find(id='qna'))</code></pre>
<p>There is no find_all() function for id because id can be given to only one element.</p>
<h4>Getting text from tags(text/get_text()):</h4>
<p>When we write <strong>soup.find(‘element’)</strong> it returns the whole tag like this:</p>
<pre class="language-markup"><code>&lt;title&gt;Web Scraping Tutorial using Python and BeautifulSoup in Hindi - Code With Harry&lt;/title&gt;</code></pre>
<p>But if we write:</p>
<pre class="language-python"><code>soup.find(‘element’).text
# OR
soup.find(‘element’).get_text()</code></pre>
<p>It will return:</p>
<pre class="language-markup"><code>Web Scraping Tutorial using Python and BeautifulSoup in Hindi - Code With Harry</code></pre>
<h4>Getting all the links:</h4>
<p>With the information I have mentioned till now, you can do it yourself. You can try it. But if unable to do then keep reading. If we want all the links from a webpage then we have to use find_all() function. The tag for links is anchor tag. So, code would be:</p>
<pre class="language-python"><code>anchors = soup.find_all('a')</code></pre>
<p>This will get all the anchor tags but anchor tags have text in them. Links are in href and href is a variable written in the tag. What did I tell you about getting variables from tags? Slicing! It can be done like this:</p>
<pre class="language-python"><code>for i in paras:
    print(i['href'])</code></pre>
<p>I also told you that we need to iterate find_all() that’s why for loop. It can also be done like:</p>
<pre class="language-python"><code>for i in paras:
    print(i.get('href'))</code></pre>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>Taking HTML from a variable instead of requests:</h4>
<p>Bs4 just needs the HTML. It doesn't matter where it came from. We can also make a variable, write HTML in that and give it to bs4. It can be done like this:</p>
<pre class="language-python"><code>html = '''
&lt;body&gt;
    &lt;ul&gt;
        &lt;li&gt;This&lt;/li&gt;
        &lt;li&gt;&lt;a&gt;This&lt;/a&gt;This&lt;/li&gt;
        &lt;li&gt;This&lt;/li&gt;
        &lt;li&gt;This&lt;/li&gt;
        &lt;li id="li"&gt;This&lt;/li&gt;
        &lt;li&gt;    This    &lt;/li&gt;
    &lt;/ul&gt;
&lt;/body&gt;
'''
soup = BeautifulSoup(html, 'html.parser')</code></pre>
<p>We made a multi-line string and put it in the html variable then we gave that to beautifulsoup. For convenience in the rest of the codes shown below we will use this HTML instead of getting it through requests.</p>
<h4>Contents:</h4>
<p>If we want to go one step deeper in the tree then we use contents. Eg:-</p>
<p>If this is the HTML code:</p>
<pre class="language-markup"><code>&lt;ul&gt;
    &lt;li&gt;This&lt;/li&gt;
    &lt;li&gt;&lt;a&gt;This&lt;/a&gt;This&lt;/li&gt;
    &lt;li&gt;This&lt;/li&gt;
    &lt;li&gt;This&lt;/li&gt;
    &lt;li&gt;This&lt;/li&gt;
&lt;/ul&gt;</code></pre>
<p>and we have targeted ul tag but we want to go inside ul then we can simply write:</p>
<pre class="language-python"><code>ul = soup.find("ul")
print(ul.contents)</code></pre>
<p>It will return a list which we can iterate.</p>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>Children, parent, next_sibling and previous_siblings:</h4>
<p>You can see HTML tree like a family tree. In a family tree there are parents, children, siblings, exactly like that in HTML tree we have children, parent and siblings. You can understand it like children means one step inside the tree, parent means one step outside the tree and siblings mean in the same step, other elements. Here is a simple code to understand it better:</p>
<pre class="language-markup"><code>&lt;body&gt;
    &lt;ul&gt;
        &lt;li&gt;This&lt;/li&gt;
        &lt;li&gt;&lt;a&gt;This&lt;/a&gt;This&lt;/li&gt;
        &lt;li&gt;This&lt;/li&gt;
        &lt;li&gt;This&lt;/li&gt;
        &lt;li&gt;This&lt;/li&gt;
    &lt;/ul&gt;
&lt;/body&gt;</code></pre>
<p>Here body is parent to ul and ul is parent to li. li is children to ul and ul is children to body. All li tags are each others siblings, easy way to understand is their parent(ul) is same so siblings. Code for all three is:</p>
<h4>1. Children:</h4>
<pre class="language-python"><code>ul = soup.find("ul")
for i in ul.children:
	print(i)</code></pre>
<p>With for loop we are iterating ul.children. For more info read <a href="#dbcc">‘Difference between Children and Contents’</a></p>
<h4>2. Parent:</h4>
<pre class="language-python"><code>ul = soup.find("ul")
print(ul.parent)</code></pre>
<p>You just have to write “.parent”, to get parent of parent, write:</p>
<pre class="language-python"><code>print(ul.parent.parent)</code></pre>
<p>Simple!</p>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>3. next_sibling and previous_siblings:</h4>
<p>Like parent we can go to next sibling and then next sibling like this:</p>
<pre class="language-python"><code>ul = soup.find(id="li")
print(ul.next_sibling.next_sibling)</code></pre>
<p>We can also get all siblings by next_siblings() function. This functions gives a generator because of which we have to iterate it, which means code would be like:</p>
<pre class="language-python"><code>ul = soup.find(id="li")

for j in ul.next_siblings:
    print(j)</code></pre>
<p>There is also a function named previous_siblings() to get previous siblings. Code is like this:</p>
<pre class="language-python"><code>for i in ul.previous_siblings:
    print(i)</code></pre>
<p>Like next_sibling, we can also use previous_sibling() function and code is similar like earlier:</p>
<pre class="language-python"><code>print(ul.previous_sibling.previous_sibling)</code></pre>
<h4>Difference between Children and Contents:</h4>
<p>Children and content are no different. The only difference is content returns a list but children gives a generator. If we print contents we can just see the list but if we print children we see:</p>
<pre class="language-python"><code>&lt;list_iterator object at 0x000002532ABDF190&gt;</code></pre>
<p>This is an object which is iterable so if we want to get values from it then we just have to iterate it by using a for loop. But <strong>why generator? When to use contents and when to use children? </strong>Contents simply takes whatever is there and store it in memory but generator doesn’t store it, it only processes when we ask for the value and it processes on the fly because of which there is no storage happening which helps when we have to scrap big data. If we scrap big data with contents, it will store everything and fill up our memory because of which code may crash. So at that time we can use children. This was a brief explanation on generator if you want to know in detail you can check out this <a href="../intermediate-python-5/index.html" target="_blank" rel="noopener">blog</a>!</p>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>stripped_strings:</h4>
<p>stripped_strings does the same thing which in-built strip() function does. It takes away all the spaces. For eg:-</p>
<pre class="language-python"><code>ul = soup.find(id="li")
elem = ul.next_sibling.next_sibling
print(elem)
for i in elem.stripped_strings:
    print(i)</code></pre>
<p>We have only one element in ul but even then we are using for loop because stripped_strings gives a generator. Output:</p>
<pre class="language-markup"><code>&lt;li&gt;    This    &lt;/li&gt;
This</code></pre>
<p>See it took away all the spaces.</p>
<h4>exit():</h4>
<p>exit() function is used to exit a program. It is helpful while finding errors or when we want to see code in pieces. If you have written a code of say 100 lines and on 71st line you have written exit() then it will not compile rest of the 29 lines, it will exit right there.</p>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>Writing data in CSV:</h4>
<p>CSV is a comma separated file which makes writing data very easy. There are two ways of writing data in CSV. Both ways are as follows:</p>
<ol>
<li>In this we will open a file and close it. We don’t have to create the file, it will automatically create it.
<pre class="language-python"><code>f = open("file.csv", "w")
f.write("Every,word,will,go,in,separate,column\n")
f.write("This,will,go,in,next,row")
f.close()​</code></pre>
</li>
<li>In this we will open a file but we don’t have to close it, it will be handled automatically. File will also be automatically created.
<pre class="language-python"><code>with open("file.csv", "w") as f:
    f.write("Every,word,will,go,in,separate,column\n")
    f.write("This,will,go,in,next,row")</code></pre>
<ul>
<li>We open the file, in arguments gave it a name with file format. Second argument, i.e. “w” means write format. There are different formats for different things like “r” for reading.</li>
<li>write() function helps us to write in file. Whatever we want to write, we pass through write() function.</li>
<li>Close() function is very important, until your file is not closed, your no data is saved. After closing the file, the file is made. So closing it is very important. In 2<sup>nd</sup> method it’s automatic so we don’t have to worry.</li>
</ul>
</li>
</ol>
<p><strong>Tip: </strong>If you need to hit and try your code and you don't want to run your program again and again because of request.get() or any reason, you can use this tip. This tip helped me alot.</p>
<p>Open your terminal and write:</p>
<pre class="language-python"><code>python -i filename.py    # write file name with format(.py)</code></pre>
<p>This command will not let the program end. You can keep writing code in the <strong>terminal</strong> and it will play that code right there.</p>
<p></p></div></div><div><app-adsense adtype="ad" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="7409118598" class="adsbygoogle" style="display: inline-block; width: 250px; height: 200px;"></ins></div><!----><!----><!----><!----></div></app-adsense><div>
<h4>Code as described/written in the video</h4>
<pre class="language-python"><code># If you want to scrape a website:
# 1. Use the API
# 2. HTML Web Scraping using some tool like bs4

# Step 0: Install all the requirements
# pip install requests
# pip install bs4
# pip install html5lib

import requests
from bs4 import BeautifulSoup
url = "https://codewithharry.com"

# Step 1: Get the HTML
r = requests.get(url)
htmlContent = r.content
# print(htmlContent)

# Step 2: Parse the HTML
soup = BeautifulSoup(htmlContent, 'html.parser')
# print(soup.prettify)

# Step 3: HTML Tree traversal
# 
# Commonly used types of objects:
# print(type(title)) # 1. Tag
# print(type(title.string)) # 2. NavigableString
# print(type(soup)) # 3. BeautifulSoup
# # 4. Comment
# markup = "&lt;p&gt;&lt;!-- this is a comment --&gt;&lt;/p&gt;"
# soup2 = BeautifulSoup(markup)
# print(type(soup2.p.string))


# Get the title of the HTML page
title = soup.title

# Get all the paragraphs from the page
paras = soup.find_all('p')
# print(paras)

# print(anchors)

# Get first element in the HTML page
# print(soup.find('p') ) 

# Get classes of any element in the HTML page
# print(soup.find('p')['class'])

# find all the elements with class lead
# print(soup.find_all("p", class_="lead"))

# Get the text from the tags/soup
# print(soup.find('p').get_text())
# print(soup.get_text())

# Get all the anchor tags from the page
anchors = soup.find_all('a')
all_links = set()
# Get all the links on the page:
for link in anchors:
    if(link.get('href') != '#'): 
        linkText = "https://codewithharry.com" +link.get('href')
        all_links.add(link)
        # print(linkText)

navbarSupportedContent = soup.find(id='navbarSupportedContent')

# .contents - A tag's children are available as a list
# .children - A tag's children are available as a generator
# for elem in navbarSupportedContent.contents:
#     print(elem)
 
# for item in navbarSupportedContent.strings:
#     print(item)

# for item in navbarSupportedContent.stripped_strings:
#     print(item)

# print(navbarSupportedContent.parent)
# for item in navbarSupportedContent.parents: 
#     print(item.name)

# print(navbarSupportedContent.next_sibling.next_sibling)
# print(navbarSupportedContent.previous_sibling.previous_sibling)

# elem = soup.select('.modal-footer')
# print(elem)
elem = soup.select('#loginModal')[0] 
print(elem)

</code></pre></div></div><!----><!----><!----></div><div class="advh mb-2"><app-adsense adtype="advh" _nghost-sc50=""><div _ngcontent-sc50="" class="text-center"><!----><!----><!----><div _ngcontent-sc50="" class="text-center"><ins _ngcontent-sc50="" data-ad-client="ca-pub-9655830461045889" data-ad-slot="8999979664" data-ad-format="auto" data-full-width-responsive="true" class="adsbygoogle" style="display: block;"></ins></div><!----></div></app-adsense></div><!----><div class="my-4 d-flex justify-content-between"><a class="btn btn-danger" href="../android-development-tutorial-in-one-video-hindi/index.html">← Previous </a><a class="btn btn-danger" href="../learn-javascript-in-one-video-in-7/index.html">Next →</a></div></div><!----></div><div id="qna" role="tabpanel" aria-labelledby="qna-tab" class="tab-pane fade mx-4 mt-3"><h3>You need to be logged in to post a comment!</h3><!----><!----><div class="container my-4 px-0"><h3>Comments</h3><!----><!----><div class="comments"><div class="row mt-4"><div class="col-sm-3 col-lg-1 col-xl-1"><img width="25%" src="../../assets/img/comment.png" class="w-100 d-block mx-auto rounded-circle"></div><div class="col-md-8 col-lg-10 col-xl-10 commentContainer"><div class="my-2 mx-2"><b>sameersaha </b><span class="badge badge-secondary"> Apr 14, 2020</span><br><div class="commentPre">hello bhai,
 Webscraping ke related ek problem hai ki, internet pe kuch websites hai, jisko ki hum scrap nahi kar sakte. To us type ke website me proxy laga ke kaise scrap kare.
For e.g. www.justdial.com , scraping allow nahi karata. To iss situation me scraping kaise kare using python.

Lots of love bro.. Please make a video on this or reply me with a solution.

Thank You.</div></div><!----><div class="collapse" id="openReply719"><form novalidate="" class="ng-untouched ng-pristine ng-invalid"><textarea type="text" maxlength="250" placeholder="Write a reply..." name="reply" minlength="4" required="" class="form-control my-2 ng-untouched ng-pristine ng-invalid" value=""></textarea><button type="submit" class="btn btn-sm btn-danger" disabled="">Reply</button><!----></form></div><!----><!----></div></div></div><div class="comments"><div class="row mt-4"><div class="col-sm-3 col-lg-1 col-xl-1"><img width="25%" src="../../assets/img/comment.png" class="w-100 d-block mx-auto rounded-circle"></div><div class="col-md-8 col-lg-10 col-xl-10 commentContainer"><div class="my-2 mx-2"><b>yasho </b><span class="badge badge-secondary"> Dec 18, 2019</span><br><div class="commentPre">please add more advanced web scraping tutorials , i want to use it for jarvis</div></div><!----><div class="collapse" id="openReply331"><form novalidate="" class="ng-untouched ng-pristine ng-invalid"><textarea type="text" maxlength="250" placeholder="Write a reply..." name="reply" minlength="4" required="" class="form-control my-2 ng-untouched ng-pristine ng-invalid" value=""></textarea><button type="submit" class="btn btn-sm btn-danger" disabled="">Reply</button><!----></form></div><!----><!----></div></div></div><!----><!----></div></div><div id="resources" role="tabpanel" aria-labelledby="resources-tab" class="tab-pane fade mx-4 mt-3"><div class="container px-0"><h4>Resources</h4><div>No resource files associated with this project</div><!----><ol><!----></ol></div></div><div id="announcements" role="tabpanel" aria-labelledby="announcements-tab" class="tab-pane fade mx-4 mt-3"><div class="container"><h4>Course Announcements</h4><p> Any Course related announcements will be posted here </p></div></div></div></div></div></div></app-video-page><!----></div><app-footer _ngcontent-sc76="" _nghost-sc75=""><footer _ngcontent-sc75="" class="container-fluid bg-dark my-0 py-3 text-light"><p _ngcontent-sc75="" class="mb-0 text-center">Copyright © 2020-2021 CodeWithHarry.com</p></footer></app-footer></app-root>
<script src="../../runtime.7b63b9fd40098a2e8207.js" defer=""></script><script src="../../polyfills.00096ed7d93ed26ee6df.js" defer=""></script><script src="../../scripts.2558b03aa1b9660ed84d.js" defer=""></script><script src="../../main.bd8a3a7a366ac101c3dc.js" defer=""></script>


<script id="serverApp-state" type="application/json">{&q;G.https://api.codewithharry.com/video/getvideo/python-web-scraping-tutorial-in-hindi?&q;:{&q;body&q;:{&q;title&q;:&q;Web Scraping Tutorial using Python and BeautifulSoup&q;,&q;videoId&q;:&q;uufDGjTuq34&q;,&q;announcements&q;:&q;&q;,&q;content&q;:&q;&l;h4&g;Introduction:&l;/h4&g;\n&l;p&g;In this blog we will learn web scrapping from start to end. We will cover topics like:&l;/p&g;\n&l;ul&g;\n&l;li&g;&l;a href=\&q;#webback\&q;&g;How does a website works in the backend?&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#webscr\&q;&g;What is web scrapping?&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#insmod\&q;&g;Installing modules:&l;/a&g;\n&l;ul style=\&q;list-style-type: circle;\&q;&g;\n&l;li&g;&l;a href=\&q;#usemod\&q;&g;Why use modules?&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#howins\&q;&g;How to install modules?&l;/a&g;&l;/li&g;\n&l;/ul&g;\n&l;/li&g;\n&l;li&g;&l;a href=\&q;#req\&q;&g;Requests&l;/a&g;\n&l;ul style=\&q;list-style-type: circle;\&q;&g;\n&l;li&g;&l;a href=\&q;#getdata\&q;&g;Getting data(HTML)&l;/a&g;&l;/li&g;\n&l;/ul&g;\n&l;/li&g;\n&l;li&g;&l;a href=\&q;mainbs4\&q;&g;BeautifulSoup (bs4)&l;/a&g;\n&l;ul style=\&q;list-style-type: circle;\&q;&g;\n&l;li&g;&l;a href=\&q;#pardata\&q;&g;Parsing Data&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#htmltt\&q;&g;HTML Tree Traversal (Targeting Data)&l;/a&g;\n&l;ul style=\&q;list-style-type: square;\&q;&g;\n&l;li&g;&l;a href=\&q;#ofir\&q;&g;Our First Code(Getting title)&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#find\&q;&g;find()&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#fall\&q;&g;find_all()&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#gcae\&q;&g;Getting class of an element&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#fecn\&q;&g;Finding elements through class name&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#feid\&q;&g;Finding elements through element ID&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#gtgt\&q;&g;Getting text from tags(text/get_text())&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#gatl\&q;&g;Getting all the links&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#thtmlreq\&q;&g;Taking HTML from a variable instead of requests&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#cont\&q;&g;Contents&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#cpnp\&q;&g;Children, parent, next_sibling and previous_siblings&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#dbcc\&q;&g;Difference between children and contents&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#sdss\&q;&g;stripped_strings&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#exit\&q;&g;exit()&l;/a&g;&l;/li&g;\n&l;/ul&g;\n&l;/li&g;\n&l;/ul&g;\n&l;/li&g;\n&l;li&g;&l;a href=\&q;#wcsv\&q;&g;Writing data in CSV file&l;/a&g;&l;/li&g;\n&l;li&g;&l;a href=\&q;#tip\&q;&g;Tip&l;/a&g;&l;/li&g;\n&l;/ul&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4 id=\&q;webback\&q;&g;How does a website works in the backend?&l;/h4&g;\n&l;p&g;Step 1: User requests a page. Eg:- &l;a href=\&q;http://www.google.com\&q;&g;www.google.com&l;/a&g;&l;/p&g;\n&l;p&g;Step 2: On whichever server the data is, that server sends you back a raw html file.&l;/p&g;\n&l;p&g;&l;img src=\&q;https://api.codewithharry.com/media/videoSeriesFiles/courseFiles/python-web-scraping-tutorial-in-hindi/files.jpg\&q; alt=\&q;\&q; width=\&q;1366\&q; height=\&q;621\&q; /&g;&l;/p&g;\n&l;p&g;&l;img src=\&q;https://api.codewithharry.com/media/videoSeriesFiles/courseFiles/python-web-scraping-tutorial-in-hindi/htmlreturn.jpg\&q; alt=\&q;\&q; width=\&q;1366\&q; height=\&q;621\&q; /&g;&l;/p&g;\n&l;p&g;Step 3: Web browser converts the html file into a readable webpage(the one that you are seeing right now).&l;/p&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4 id=\&q;webscr\&q;&g;What is web scrapping?&l;/h4&g;\n&l;p&g;The technique of taking the html file sent by the server into python and scrapping it instead of giving it to the browser and displaying it is called Web scrapping.&l;/p&g;\n&l;p&g;Two ways of getting data from a website:&l;/p&g;\n&l;ol&g;\n&l;li&g;Using API&l;/li&g;\n&l;li&g;HTML web scrapping using some tool like bs4&l;/li&g;\n&l;/ol&g;\n&l;h4 id=\&q;insmod\&q;&g;Installing modules:&l;/h4&g;\n&l;h5 id=\&q;usemod\&q;&g;Why use modules?&l;/h5&g;\n&l;p&g;In order to use the power of python to scrap websites, we don&a;rsquo;t have to write new code for everything. We can use existing code written by experts. Why take the hard path when the outcome is same, when you can do it easily in some lines of code in very short period of time?&l;/p&g;\n&l;h5 id=\&q;howins\&q;&g;How to install modules?&l;/h5&g;\n&l;p&g;Modules are very easy to install. Open command prompt and just write these three lines one by one:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;pip install requests\npip install html5lib\npip install bs4&l;/code&g;&l;/pre&g;\n&l;p&g;and you are good to go! If you get any error you can watch this video:&l;/p&g;\n&l;p style=\&q;text-align: center;\&q;&g;&l;a href=\&q;../../videos/general-python-errors-1\&q; target=\&q;_blank\&q; rel=\&q;noopener\&q;&g;https://www.codewithharry.com/videos/general-python-errors-1&l;/a&g;&l;/p&g;\n&l;h4 id=\&q;req\&q;&g;Requests:&l;/h4&g;\n&l;ul&g;\n&l;li&g;\n&l;h5 id=\&q;getdata\&q;&g;Getting data(HTML):&l;/h5&g;\n&l;/li&g;\n&l;/ul&g;\n&l;p&g;In order to work with the HTML, we will have to get the HTML as a string. We can easily get HTML data by using get() function in requests module. We first need to import this module by writing:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;import requests&l;/code&g;&l;/pre&g;\n&l;p&g;Then we can make a variable or directly write the link in get() function as a string:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;url = \&q;https://codewithharry.com\&q;\nr = requests.get(url)\t\t# r variable has all the HTML code\nhtmlContent = r.content\t# r returns response so if we want the code we write r.content\nprint(htmlContent)\t\t# printing the code&l;/code&g;&l;/pre&g;\n&l;p&g;&l;img src=\&q;https://api.codewithharry.com/media/videoSeriesFiles/courseFiles/python-web-scraping-tutorial-in-hindi/content.jpg\&q; alt=\&q;\&q; width=\&q;1306\&q; height=\&q;621\&q; /&g;&l;/p&g;\n&l;p&g;Instead of &a;ldquo;content&a;rdquo; we can also use &a;ldquo;text&a;rdquo;:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;htmlTexr = r.text\nprint(htmlText)&l;/code&g;&l;/pre&g;\n&l;p&g;&l;img src=\&q;https://api.codewithharry.com/media/videoSeriesFiles/courseFiles/python-web-scraping-tutorial-in-hindi/text.jpg\&q; alt=\&q;\&q; width=\&q;1311\&q; height=\&q;639\&q; /&g;&l;/p&g;\n&l;p&g;r.text is the response in &l;strong&g;Unicode&l;/strong&g; and r.content is the response in &l;strong&g;bytes&l;/strong&g;.&l;/p&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4 id=\&q;mainbs4\&q;&g;BeautifulSoup (bs4):&l;/h4&g;\n&l;p&g;Beautiful Soup is the perfect module to parse or transverse through HTML code. We can easily target any div, table, td, tr, class, id, etc. The basic template(boilerplate code) which is used everytime is:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;import requests\nfrom bs4 import BeautifulSoup\nurl = \&q;https://codewithharry.com\&q;\n\nr = requests.get(url)\nsoup = BeautifulSoup(r.content, &s;html.parser&s;)\n\nprint(soup.prettify())\t# to print html in tree structure&l;/code&g;&l;/pre&g;\n&l;h4 id=\&q;pardata\&q;&g;Parsing Data:&l;/h4&g;\n&l;p&g;Once the HTML is fetched using requests the next step will be to parse the HTML content. For that we will use python&a;rsquo;s BeautifulSoup module which will create a tree like structure for our DOM. This line is parsing the data:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;soup = BeautifulSoup(htmlContent, &s;html.parser&s;)&l;/code&g;&l;/pre&g;\n&l;p&g;We have given two arguments to BeautifulSoup function. One is our HTML content another is our parser. We can also save an HTML file instead of getting data everytime, take that HTML file&a;rsquo;s data in a variable and in the same way just write the variable in the function, both are same things. In second argument we are giving it a parser. Here we are using html.parser, we can also use lxml. The parsed data is saved in our soup variable. That is our soup, a mixture of everything. All the data we want is there, we just have to target it and get it. Simple, right?&l;/p&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4 id=\&q;htmltt\&q;&g;HTML Tree Traversal (Targeting Data):&l;/h4&g;\n&l;p&g;From here the main thing starts, from here we start playing with the data. HTML Tree traversal is travelling through the tree branches(HTML tags) and to target the branches we want and scrapping them. Just for excitement wanna see something? Copy and run this code:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;import requests\nfrom bs4 import BeautifulSoup\nurl = \&q;https://www.codewithharry.com/videos/python-web-scraping-tutorial-in-hindi\&q;\n\nr = requests.get(url)\nsoup = BeautifulSoup(r.content, &s;html.parser&s;)\nfor i in soup.find_all(\&q;code\&q;):\n    print(i.text)\n    # We can also do it like this\n    # print(i.get_text())&l;/code&g;&l;/pre&g;\n&l;p&g;Yes! It scrapped all the codes on this page! See how powerful scrapping is, how much it can help you and how much time it can save! I hope you are all powered up, let&a;rsquo;s start scrapping!&l;/p&g;\n&l;h4 id=\&q;ofir\&q;&g;Our first code:&l;/h4&g;\n&l;p&g;If we want to scrap title of the page(which is shown in the tab button) then we can get it by:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;title = soup.title\nprint(title)&l;/code&g;&l;/pre&g;\n&l;p&g;There is a title tag in all HTML pages, for this page it is:&l;/p&g;\n&l;pre class=\&q;language-markup\&q;&g;&l;code&g;&a;lt;title&a;gt;Web Scraping Tutorial using Python and BeautifulSoup in Hindi - Code With Harry&a;lt;/title&a;gt;&l;/code&g;&l;/pre&g;\n&l;p&g;So with soup.title we can directly get the title of the page. soup.title is like saying soup&a;gt;title, going inside soup and getting title. In windows like we go into folders like that soup/title. If say there is code:&l;/p&g;\n&l;pre class=\&q;language-markup\&q;&g;&l;code&g;&a;lt;div&a;gt;\n    &a;lt;div&a;gt;\n        &a;lt;code&a;gt;\n            This is file.\n        &a;lt;/code&a;gt;\n    &a;lt;/div&a;gt;\n&a;lt;/div&a;gt;&l;/code&g;&l;/pre&g;\n&l;p&g;We can get data of code tag by simply writing &a;ldquo;soup.div.div.code&a;rdquo;. It&a;rsquo;s like giving path of a file through folders where every tag is a folder and whatever is in code tag is the file.&l;/p&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4 id=\&q;find\&q;&g;find():&l;/h4&g;\n&l;p&g;It is used to get first element in the HTML page. It could be any element. For eg:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;print(soup.find(&s;p&s;)) &l;/code&g;&l;/pre&g;\n&l;p&g;This line will get you first p tag of the page. If we want all paragraphs(all p tags) of the page then we can use find_all() function.&l;/p&g;\n&l;h4 id=\&q;fall\&q;&g;find_all():&l;/h4&g;\n&l;p&g;This line will get you all p tags of the page:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;paras = soup.find_all(&s;p&s;)\nprint(paras)&l;/code&g;&l;/pre&g;\n&l;p&g;Whatever tag you want to scrap, write that tag in the function as argument. Also when we print paras variable,&a;nbsp; it will print it like a list. If we want every item one by one, we just put it through a for loop and iterate it, like this:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;for i in paras:\n    print(i)&l;/code&g;&l;/pre&g;\n&l;p&g;gcae fecn feid gtgt gatl cont cpnp dbcc sdss&l;/p&g;\n&l;h4 id=\&q;gcae\&q;&g;Getting class of an element:&l;/h4&g;\n&l;p&g;Earlier we were getting text from the tag, this time we are getting class of the element. To get class of an element we need to write:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;# print(soup.find(&s;p&s;)[&s;class&s;])&l;/code&g;&l;/pre&g;\n&l;p&g;Here we are using find() function to get p tag like before but we added [&a;lsquo;class&a;rsquo;] in it. It&a;rsquo;s like list slicing, tag has a class variable, we are getting that variable&a;rsquo;s value. If we want other variables like id, style, role, type, &l;strong&g;we can get them all&l;/strong&g;.&l;/p&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4 id=\&q;fecn\&q;&g;Finding elements through class name:&l;/h4&g;\n&l;p&g;Most of the times we don&a;rsquo;t want to find by tag name because it isn&a;rsquo;t that accurate so we use class name there. Code to find elements by class name:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;# print(soup.find_all(\&q;p\&q;, class_=\&q;lead\&q;))&l;/code&g;&l;/pre&g;\n&l;p&g;We can also avoid writing tag name if you are not sure about tag name. You can simply write like:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;# print(soup.find_all(class_=\&q;code-toolbar\&q;))&l;/code&g;&l;/pre&g;\n&l;h4 id=\&q;feid\&q;&g;Finding elements through element ID:&l;/h4&g;\n&l;p&g;Sometimes some elements are not given classes or we just want to target the element with id. We can do it like this:-&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;# print(soup.find(id=&s;qna&s;))&l;/code&g;&l;/pre&g;\n&l;p&g;There is no find_all() function for id because id can be given to only one element.&l;/p&g;\n&l;h4 id=\&q;gtgt\&q;&g;Getting text from tags(text/get_text()):&l;/h4&g;\n&l;p&g;When we write &l;strong&g;soup.find(&a;lsquo;element&a;rsquo;)&l;/strong&g; it returns the whole tag like this:&l;/p&g;\n&l;pre class=\&q;language-markup\&q;&g;&l;code&g;&a;lt;title&a;gt;Web Scraping Tutorial using Python and BeautifulSoup in Hindi - Code With Harry&a;lt;/title&a;gt;&l;/code&g;&l;/pre&g;\n&l;p&g;But if we write:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;soup.find(&a;lsquo;element&a;rsquo;).text\n# OR\nsoup.find(&a;lsquo;element&a;rsquo;).get_text()&l;/code&g;&l;/pre&g;\n&l;p&g;It will return:&l;/p&g;\n&l;pre class=\&q;language-markup\&q;&g;&l;code&g;Web Scraping Tutorial using Python and BeautifulSoup in Hindi - Code With Harry&l;/code&g;&l;/pre&g;\n&l;h4 id=\&q;gatl\&q;&g;Getting all the links:&l;/h4&g;\n&l;p&g;With the information I have mentioned till now, you can do it yourself. You can try it. But if unable to do then keep reading. If we want all the links from a webpage then we have to use find_all() function. The tag for links is anchor tag. So, code would be:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;anchors = soup.find_all(&s;a&s;)&l;/code&g;&l;/pre&g;\n&l;p&g;This will get all the anchor tags but anchor tags have text in them. Links are in href and href is a variable written in the tag. What did I tell you about getting variables from tags? Slicing! It can be done like this:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;for i in paras:\n    print(i[&s;href&s;])&l;/code&g;&l;/pre&g;\n&l;p&g;I also told you that we need to iterate find_all() that&a;rsquo;s why for loop. It can also be done like:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;for i in paras:\n    print(i.get(&s;href&s;))&l;/code&g;&l;/pre&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4 id=\&q;thtmlreq\&q;&g;Taking HTML from a variable instead of requests:&l;/h4&g;\n&l;p&g;Bs4 just needs the HTML. It doesn&s;t matter where it came from. We can also make a variable, write HTML in that and give it to bs4. It can be done like this:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;html = &s;&s;&s;\n&a;lt;body&a;gt;\n    &a;lt;ul&a;gt;\n        &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n        &a;lt;li&a;gt;&a;lt;a&a;gt;This&a;lt;/a&a;gt;This&a;lt;/li&a;gt;\n        &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n        &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n        &a;lt;li id=\&q;li\&q;&a;gt;This&a;lt;/li&a;gt;\n        &a;lt;li&a;gt;    This    &a;lt;/li&a;gt;\n    &a;lt;/ul&a;gt;\n&a;lt;/body&a;gt;\n&s;&s;&s;\nsoup = BeautifulSoup(html, &s;html.parser&s;)&l;/code&g;&l;/pre&g;\n&l;p&g;We made a multi-line string and put it in the html variable then we gave that to beautifulsoup. For convenience in the rest of the codes shown below we will use this HTML instead of getting it through requests.&l;/p&g;\n&l;h4 id=\&q;cont\&q;&g;Contents:&l;/h4&g;\n&l;p&g;If we want to go one step deeper in the tree then we use contents. Eg:-&l;/p&g;\n&l;p&g;If this is the HTML code:&l;/p&g;\n&l;pre class=\&q;language-markup\&q;&g;&l;code&g;&a;lt;ul&a;gt;\n    &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n    &a;lt;li&a;gt;&a;lt;a&a;gt;This&a;lt;/a&a;gt;This&a;lt;/li&a;gt;\n    &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n    &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n    &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n&a;lt;/ul&a;gt;&l;/code&g;&l;/pre&g;\n&l;p&g;and we have targeted ul tag but we want to go inside ul then we can simply write:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;ul = soup.find(\&q;ul\&q;)\nprint(ul.contents)&l;/code&g;&l;/pre&g;\n&l;p&g;It will return a list which we can iterate.&l;/p&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4 id=\&q;cpnp\&q;&g;Children, parent, next_sibling and previous_siblings:&l;/h4&g;\n&l;p&g;You can see HTML tree like a family tree. In a family tree there are parents, children, siblings, exactly like that in HTML tree we have children, parent and siblings. You can understand it like children means one step inside the tree, parent means one step outside the tree and siblings mean in the same step, other elements. Here is a simple code to understand it better:&l;/p&g;\n&l;pre class=\&q;language-markup\&q;&g;&l;code&g;&a;lt;body&a;gt;\n    &a;lt;ul&a;gt;\n        &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n        &a;lt;li&a;gt;&a;lt;a&a;gt;This&a;lt;/a&a;gt;This&a;lt;/li&a;gt;\n        &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n        &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n        &a;lt;li&a;gt;This&a;lt;/li&a;gt;\n    &a;lt;/ul&a;gt;\n&a;lt;/body&a;gt;&l;/code&g;&l;/pre&g;\n&l;p&g;Here body is parent to ul and ul is parent to li. li is children to ul and ul is children to body. All li tags are each others siblings, easy way to understand is their parent(ul) is same so siblings. Code for all three is:&l;/p&g;\n&l;h4&g;1. Children:&l;/h4&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;ul = soup.find(\&q;ul\&q;)\nfor i in ul.children:\n\tprint(i)&l;/code&g;&l;/pre&g;\n&l;p&g;With for loop we are iterating ul.children. For more info read &l;a href=\&q;#dbcc\&q;&g;&a;lsquo;Difference between Children and Contents&a;rsquo;&l;/a&g;&l;/p&g;\n&l;h4&g;2. Parent:&l;/h4&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;ul = soup.find(\&q;ul\&q;)\nprint(ul.parent)&l;/code&g;&l;/pre&g;\n&l;p&g;You just have to write &a;ldquo;.parent&a;rdquo;, to get parent of parent, write:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;print(ul.parent.parent)&l;/code&g;&l;/pre&g;\n&l;p&g;Simple!&l;/p&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4&g;3. next_sibling and previous_siblings:&l;/h4&g;\n&l;p&g;Like parent we can go to next sibling and then next sibling like this:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;ul = soup.find(id=\&q;li\&q;)\nprint(ul.next_sibling.next_sibling)&l;/code&g;&l;/pre&g;\n&l;p&g;We can also get all siblings by next_siblings() function. This functions gives a generator because of which we have to iterate it, which means code would be like:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;ul = soup.find(id=\&q;li\&q;)\n\nfor j in ul.next_siblings:\n    print(j)&l;/code&g;&l;/pre&g;\n&l;p&g;There is also a function named previous_siblings() to get previous siblings. Code is like this:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;for i in ul.previous_siblings:\n    print(i)&l;/code&g;&l;/pre&g;\n&l;p&g;Like next_sibling, we can also use previous_sibling() function and code is similar like earlier:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;print(ul.previous_sibling.previous_sibling)&l;/code&g;&l;/pre&g;\n&l;h4 id=\&q;dbcc\&q;&g;Difference between Children and Contents:&l;/h4&g;\n&l;p&g;Children and content are no different. The only difference is content returns a list but children gives a generator. If we print contents we can just see the list but if we print children we see:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;&a;lt;list_iterator object at 0x000002532ABDF190&a;gt;&l;/code&g;&l;/pre&g;\n&l;p&g;This is an object which is iterable so if we want to get values from it then we just have to iterate it by using a for loop. But &l;strong&g;why generator? When to use contents and when to use children? &l;/strong&g;Contents simply takes whatever is there and store it in memory but generator doesn&a;rsquo;t store it, it only processes when we ask for the value and it processes on the fly because of which there is no storage happening which helps when we have to scrap big data. If we scrap big data with contents, it will store everything and fill up our memory because of which code may crash. So at that time we can use children. This was a brief explanation on generator if you want to know in detail you can check out this &l;a href=\&q;../../videos/intermediate-python-5\&q; target=\&q;_blank\&q; rel=\&q;noopener\&q;&g;blog&l;/a&g;!&l;/p&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4 id=\&q;sdss\&q;&g;stripped_strings:&l;/h4&g;\n&l;p&g;stripped_strings does the same thing which in-built strip() function does. It takes away all the spaces. For eg:-&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;ul = soup.find(id=\&q;li\&q;)\nelem = ul.next_sibling.next_sibling\nprint(elem)\nfor i in elem.stripped_strings:\n    print(i)&l;/code&g;&l;/pre&g;\n&l;p&g;We have only one element in ul but even then we are using for loop because stripped_strings gives a generator. Output:&l;/p&g;\n&l;pre class=\&q;language-markup\&q;&g;&l;code&g;&a;lt;li&a;gt;    This    &a;lt;/li&a;gt;\nThis&l;/code&g;&l;/pre&g;\n&l;p&g;See it took away all the spaces.&l;/p&g;\n&l;h4 id=\&q;exit\&q;&g;exit():&l;/h4&g;\n&l;p&g;exit() function is used to exit a program. It is helpful while finding errors or when we want to see code in pieces. If you have written a code of say 100 lines and on 71st line you have written exit() then it will not compile rest of the 29 lines, it will exit right there.&l;/p&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4 id=\&q;wcsv\&q;&g;Writing data in CSV:&l;/h4&g;\n&l;p&g;CSV is a comma separated file which makes writing data very easy. There are two ways of writing data in CSV. Both ways are as follows:&l;/p&g;\n&l;ol&g;\n&l;li&g;In this we will open a file and close it. We don&a;rsquo;t have to create the file, it will automatically create it.\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;f = open(\&q;file.csv\&q;, \&q;w\&q;)\nf.write(\&q;Every,word,will,go,in,separate,column\\n\&q;)\nf.write(\&q;This,will,go,in,next,row\&q;)\nf.close()​&l;/code&g;&l;/pre&g;\n&l;/li&g;\n&l;li&g;In this we will open a file but we don&a;rsquo;t have to close it, it will be handled automatically. File will also be automatically created.\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;with open(\&q;file.csv\&q;, \&q;w\&q;) as f:\n    f.write(\&q;Every,word,will,go,in,separate,column\\n\&q;)\n    f.write(\&q;This,will,go,in,next,row\&q;)&l;/code&g;&l;/pre&g;\n&l;ul&g;\n&l;li&g;We open the file, in arguments gave it a name with file format. Second argument, i.e. &a;ldquo;w&a;rdquo; means write format. There are different formats for different things like &a;ldquo;r&a;rdquo; for reading.&l;/li&g;\n&l;li&g;write() function helps us to write in file. Whatever we want to write, we pass through write() function.&l;/li&g;\n&l;li&g;Close() function is very important, until your file is not closed, your no data is saved. After closing the file, the file is made. So closing it is very important. In 2&l;sup&g;nd&l;/sup&g; method it&a;rsquo;s automatic so we don&a;rsquo;t have to worry.&l;/li&g;\n&l;/ul&g;\n&l;/li&g;\n&l;/ol&g;\n&l;p id=\&q;tip\&q;&g;&l;strong&g;Tip: &l;/strong&g;If you need to hit and try your code and you don&s;t want to run your program again and again because of request.get() or any reason, you can use this tip. This tip helped me alot.&l;/p&g;\n&l;p&g;Open your terminal and write:&l;/p&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;python -i filename.py    # write file name with format(.py)&l;/code&g;&l;/pre&g;\n&l;p&g;This command will not let the program end. You can keep writing code in the &l;strong&g;terminal&l;/strong&g; and it will play that code right there.&l;/p&g;\n&l;p&g;&a;lt;|AD|&a;gt;&l;/p&g;\n&l;h4&g;Code as described/written in the video&l;/h4&g;\n&l;pre class=\&q;language-python\&q;&g;&l;code&g;# If you want to scrape a website:\n# 1. Use the API\n# 2. HTML Web Scraping using some tool like bs4\n\n# Step 0: Install all the requirements\n# pip install requests\n# pip install bs4\n# pip install html5lib\n\nimport requests\nfrom bs4 import BeautifulSoup\nurl = \&q;https://codewithharry.com\&q;\n\n# Step 1: Get the HTML\nr = requests.get(url)\nhtmlContent = r.content\n# print(htmlContent)\n\n# Step 2: Parse the HTML\nsoup = BeautifulSoup(htmlContent, &s;html.parser&s;)\n# print(soup.prettify)\n\n# Step 3: HTML Tree traversal\n# \n# Commonly used types of objects:\n# print(type(title)) # 1. Tag\n# print(type(title.string)) # 2. NavigableString\n# print(type(soup)) # 3. BeautifulSoup\n# # 4. Comment\n# markup = \&q;&a;lt;p&a;gt;&a;lt;!-- this is a comment --&a;gt;&a;lt;/p&a;gt;\&q;\n# soup2 = BeautifulSoup(markup)\n# print(type(soup2.p.string))\n\n\n# Get the title of the HTML page\ntitle = soup.title\n\n# Get all the paragraphs from the page\nparas = soup.find_all(&s;p&s;)\n# print(paras)\n\n# print(anchors)\n\n# Get first element in the HTML page\n# print(soup.find(&s;p&s;) ) \n\n# Get classes of any element in the HTML page\n# print(soup.find(&s;p&s;)[&s;class&s;])\n\n# find all the elements with class lead\n# print(soup.find_all(\&q;p\&q;, class_=\&q;lead\&q;))\n\n# Get the text from the tags/soup\n# print(soup.find(&s;p&s;).get_text())\n# print(soup.get_text())\n\n# Get all the anchor tags from the page\nanchors = soup.find_all(&s;a&s;)\nall_links = set()\n# Get all the links on the page:\nfor link in anchors:\n    if(link.get(&s;href&s;) != &s;#&s;): \n        linkText = \&q;https://codewithharry.com\&q; +link.get(&s;href&s;)\n        all_links.add(link)\n        # print(linkText)\n\nnavbarSupportedContent = soup.find(id=&s;navbarSupportedContent&s;)\n\n# .contents - A tag&s;s children are available as a list\n# .children - A tag&s;s children are available as a generator\n# for elem in navbarSupportedContent.contents:\n#     print(elem)\n \n# for item in navbarSupportedContent.strings:\n#     print(item)\n\n# for item in navbarSupportedContent.stripped_strings:\n#     print(item)\n\n# print(navbarSupportedContent.parent)\n# for item in navbarSupportedContent.parents: \n#     print(item.name)\n\n# print(navbarSupportedContent.next_sibling.next_sibling)\n# print(navbarSupportedContent.previous_sibling.previous_sibling)\n\n# elem = soup.select(&s;.modal-footer&s;)\n# print(elem)\nelem = soup.select(&s;#loginModal&s;)[0] \nprint(elem)\n\n&l;/code&g;&l;/pre&g;&q;,&q;duration&q;:&q;&q;,&q;metaTags&q;:&q;python web scraping, web scraping&q;,&q;metaDesc&q;:&q;In this tutorial we will learn about creating web scraping using python and beautiful soup&q;,&q;time&q;:&q;2021-05-17T21:09:25.375050&q;,&q;slug&q;:&q;python-web-scraping-tutorial-in-hindi&q;,&q;success&q;:true},&q;headers&q;:{&q;date&q;:[&q;Sun, 01 Aug 2021 00:06:05 GMT&q;],&q;server&q;:[&q;Apache/2.4.41 (Ubuntu)&q;],&q;vary&q;:[&q;Accept,Origin&q;],&q;allow&q;:[&q;OPTIONS, GET&q;],&q;x-frame-options&q;:[&q;DENY&q;],&q;content-length&q;:[&q;23816&q;],&q;x-content-type-options&q;:[&q;nosniff&q;],&q;referrer-policy&q;:[&q;same-origin&q;],&q;keep-alive&q;:[&q;timeout=5, max=100&q;],&q;connection&q;:[&q;Keep-Alive&q;],&q;content-type&q;:[&q;application/json&q;]},&q;status&q;:200,&q;statusText&q;:&q;OK&q;,&q;url&q;:&q;https://api.codewithharry.com/video/getvideo/python-web-scraping-tutorial-in-hindi&q;},&q;G.https://api.codewithharry.com/video/getcoursecontent/python-web-scraping-tutorial-in-hindi?&q;:{&q;body&q;:[{&q;title&q;:&q;Learn JavaScript In One Video In Hindi (2018)&q;,&q;slug&q;:&q;learn-javascript-in-one-video-in-hindi&q;},{&q;title&q;:&q;Learn Python In Hindi In One Video - हिंदी में (Latest Tutorial)&q;,&q;slug&q;:&q;learn-python-in-one-video-in-hindi&q;},{&q;title&q;:&q;Learn Php In One Video In Hindi - हिंदी में (Latest PHP Tutorial 2018)&q;,&q;slug&q;:&q;learn-php-in-one-video-in-hindi&q;},{&q;title&q;:&q;15 Minute Python Tutorial For Beginners In Hindi (Full &a; Complete Crash Course)&q;,&q;slug&q;:&q;learn-python-in-one-video-in-15-min-hindi&q;},{&q;title&q;:&q;Learn Bootstrap In Hindi In One Video - हिंदी में (Latest Tutorial 2019)&q;,&q;slug&q;:&q;learn-bootstrap-in-one-video&q;},{&q;title&q;:&q;Learn HTML In One Video&q;,&q;slug&q;:&q;learn-html-in-one-video-in-hindi&q;},{&q;title&q;:&q;Learn jQuery In Hindi In One Video - हिंदी में (Latest Tutorial 2018)&q;,&q;slug&q;:&q;learn-jquery-in-one-video-in-hindi&q;},{&q;title&q;:&q;Create A Responsive Website Using HTML, CSS And Bootstrap 4 In Hindi&q;,&q;slug&q;:&q;learn-responsive-html-css3-bootstrap-website-in-one-video-in-hindi&q;},{&q;title&q;:&q;Login And Registration Form Using Php &a; MySQL [Php Login System In Hindi]&q;,&q;slug&q;:&q;php-mysql-login-system-in-one-video&q;},{&q;title&q;:&q;C Programming Tutorial For Beginners: Learn C In Hindi&q;,&q;slug&q;:&q;learn-c-in-one-video-in-hindi&q;},{&q;title&q;:&q;JavaScript Registration Form Validation - हिंदी में (Latest Tutorial 2019)&q;,&q;slug&q;:&q;complete-form-validation-using-javascript-in-hindi-in-one-video&q;},{&q;title&q;:&q;CSS 3 Tutorial For Beginners: Learn CSS In One Video In Hindi&q;,&q;slug&q;:&q;learn-css-in-one-video-in-hindi&q;},{&q;title&q;:&q;C++ Tutorial For Beginners: Learn C Plus Plus In Hindi&q;,&q;slug&q;:&q;learn-c-plus-plus-in-one-video-in-hindi&q;},{&q;title&q;:&q;Learn Python Programming For Free | Python Programming Tutorial In Hindi&q;,&q;slug&q;:&q;learn-python-in-one-video-in-hindi-2019&q;},{&q;title&q;:&q;Java tutorial in hindi&q;,&q;slug&q;:&q;learn-java-in-one-video-in-hindi-2019&q;},{&q;title&q;:&q;Android Development Tutorial in Hindi&q;,&q;slug&q;:&q;android-development-tutorial-in-one-video-hindi&q;},{&q;title&q;:&q;Web Scraping Tutorial using Python and BeautifulSoup&q;,&q;slug&q;:&q;python-web-scraping-tutorial-in-hindi&q;},{&q;title&q;:&q;Git &a; GitHub Tutorial For Beginners In Hindi - हिंदी में (2019)&q;,&q;slug&q;:&q;learn-javascript-in-one-video-in-7&q;},{&q;title&q;:&q;Login And Registration Form Using Php &a; MySQL [Php Login System In Hindi]&q;,&q;slug&q;:&q;learn-javascript-in-one-video-in-9&q;},{&q;title&q;:&q;Linux Tutorial For Beginners in Hindi&q;,&q;slug&q;:&q;learn-javascript-in-one-video-in-12&q;},{&q;title&q;:&q;Numpy Tutorial in Hindi&q;,&q;slug&q;:&q;learn-javascript-in-one-video-in-13&q;},{&q;title&q;:&q;Php Tutorial for Beginners in Hindi with MySQL Project&q;,&q;slug&q;:&q;learn-php-in-one-video-in-hindi-2020&q;},{&q;title&q;:&q;Learn JavaScript In One Video In Hindi (2020)&q;,&q;slug&q;:&q;javascript-tutorial-in-hindi-in-one-video-2020&q;},{&q;title&q;:&q;C Language Tutorial For Beginners (With Notes)&q;,&q;slug&q;:&q;c-tutorial-in-hindi-with-notes&q;},{&q;title&q;:&q;How To Make a WordPress Website | Wordpress Tutorial for Beginners | Elementor Tutorial In Hindi&q;,&q;slug&q;:&q;wordpress-tutorial-in-hindi&q;},{&q;title&q;:&q;Python Tutorial For Beginners In Hindi (With Notes)&q;,&q;slug&q;:&q;python-tutorial-easy-for-beginners&q;},{&q;title&q;:&q;Python Programming Course in Hindi (Advanced)&q;,&q;slug&q;:&q;python-tutorial-advanced&q;},{&q;title&q;:&q;Android Application Development Tutorial in Hindi With Notes&q;,&q;slug&q;:&q;android-tutorial-in-hindi-with-notes&q;},{&q;title&q;:&q;React Tutorial in Hindi&q;,&q;slug&q;:&q;react-tutorial-in-hindi&q;},{&q;title&q;:&q;HTML Tutorial For Beginners In Hindi (With Notes)&q;,&q;slug&q;:&q;html-tutorial-for-beginners&q;},{&q;title&q;:&q;CSS Tutorial In Hindi (With Notes)&q;,&q;slug&q;:&q;css-in-one-video&q;}],&q;headers&q;:{&q;date&q;:[&q;Sun, 01 Aug 2021 00:06:05 GMT&q;],&q;server&q;:[&q;Apache/2.4.41 (Ubuntu)&q;],&q;vary&q;:[&q;Accept,Origin&q;],&q;allow&q;:[&q;OPTIONS, GET&q;],&q;x-frame-options&q;:[&q;DENY&q;],&q;content-length&q;:[&q;3596&q;],&q;x-content-type-options&q;:[&q;nosniff&q;],&q;referrer-policy&q;:[&q;same-origin&q;],&q;keep-alive&q;:[&q;timeout=5, max=100&q;],&q;connection&q;:[&q;Keep-Alive&q;],&q;content-type&q;:[&q;application/json&q;]},&q;status&q;:200,&q;statusText&q;:&q;OK&q;,&q;url&q;:&q;https://api.codewithharry.com/video/getcoursecontent/python-web-scraping-tutorial-in-hindi&q;},&q;G.https://api.codewithharry.com/video/getcomments/python-web-scraping-tutorial-in-hindi/0/999999?&q;:{&q;body&q;:[{&q;comment&q;:&q;hello bhai,\r\n Webscraping ke related ek problem hai ki, internet pe kuch websites hai, jisko ki hum scrap nahi kar sakte. To us type ke website me proxy laga ke kaise scrap kare.\r\nFor e.g. www.justdial.com , scraping allow nahi karata. To iss situation me scraping kaise kare using python.\r\n\r\nLots of love bro.. Please make a video on this or reply me with a solution.\r\n\r\nThank You.&q;,&q;username&q;:&q;sameersaha&q;,&q;sno&q;:719,&q;time&q;:&q;2020-04-14T05:45:46.071031&q;,&q;replycount&q;:0},{&q;comment&q;:&q;please add more advanced web scraping tutorials , i want to use it for jarvis&q;,&q;username&q;:&q;yasho&q;,&q;sno&q;:331,&q;time&q;:&q;2019-12-18T10:58:44.140160&q;,&q;replycount&q;:0}],&q;headers&q;:{&q;date&q;:[&q;Sun, 01 Aug 2021 00:06:05 GMT&q;],&q;server&q;:[&q;Apache/2.4.41 (Ubuntu)&q;],&q;vary&q;:[&q;Accept,Origin&q;],&q;allow&q;:[&q;OPTIONS, GET&q;],&q;x-frame-options&q;:[&q;DENY&q;],&q;content-length&q;:[&q;667&q;],&q;x-content-type-options&q;:[&q;nosniff&q;],&q;referrer-policy&q;:[&q;same-origin&q;],&q;keep-alive&q;:[&q;timeout=5, max=100&q;],&q;connection&q;:[&q;Keep-Alive&q;],&q;content-type&q;:[&q;application/json&q;]},&q;status&q;:200,&q;statusText&q;:&q;OK&q;,&q;url&q;:&q;https://api.codewithharry.com/video/getcomments/python-web-scraping-tutorial-in-hindi/0/999999&q;}}</script></body><!-- This page was prerendered with Angular Universal -->
<!-- Mirrored from www.codewithharry.com/videos/python-web-scraping-tutorial-in-hindi/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 01 Aug 2021 14:00:18 GMT -->
</html>